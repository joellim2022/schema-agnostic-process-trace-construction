{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e41fd4-d649-4149-b378-2051f28830a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10000 traces and saved tables to 'data'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import random\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# Configuration\n",
    "# ================================================================\n",
    "\n",
    "N_TRACES = 10_000\n",
    "RANDOM_SEED = 42\n",
    "DATA_DIR = \"./data\"\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# Helper: deterministic RNG\n",
    "# ================================================================\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 1. Transition graph definition\n",
    "# ================================================================\n",
    "\n",
    "def build_transition_graph() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build the transition_graph dataframe describing allowed\n",
    "    edges between event nodes.\n",
    "    \"\"\"\n",
    "    transitions = {\n",
    "        \"CustomerCreated\": [\"OrderPlaced\"],\n",
    "        \"OrderPlaced\": [\"VerificationStarted\"],\n",
    "        \"VerificationStarted\": [\n",
    "            \"VerificationAutoApproved\",\n",
    "            \"VerificationNeedsManualReview\",\n",
    "            \"VerificationFailed\",\n",
    "        ],\n",
    "        \"VerificationAutoApproved\": [\"OrderConfirmed\"],\n",
    "        \"VerificationNeedsManualReview\": [\"ManualReviewCompleted\"],\n",
    "        # Note: at runtime we choose either OrderConfirmed or OrderRejected,\n",
    "        # but both are listed here as possible successors.\n",
    "        \"ManualReviewCompleted\": [\"OrderConfirmed\", \"OrderRejected\"],\n",
    "        \"VerificationFailed\": [\"OrderRejected\"],\n",
    "        \"OrderRejected\": [],\n",
    "\n",
    "        \"OrderConfirmed\": [\"KitchenStarted\"],\n",
    "        \"KitchenStarted\": [\"KitchenCompleted\"],\n",
    "        \"KitchenCompleted\": [\"DriverAssigned\"],\n",
    "        \"DriverAssigned\": [\"DriverAtRestaurant\"],\n",
    "        \"DriverAtRestaurant\": [\"PickupComplete\"],\n",
    "        \"PickupComplete\": [\"OnTheWay\"],\n",
    "        \"OnTheWay\": [\"Delivered\"],\n",
    "\n",
    "        # Branch: with or without support issue\n",
    "        \"Delivered\": [\"PaymentAuthorized\", \"SupportTicketOpened\"],\n",
    "        \"SupportTicketOpened\": [\"VoucherIssued\"],\n",
    "        \"VoucherIssued\": [\"PaymentAuthorized\"],\n",
    "        \"PaymentAuthorized\": [\"PaymentCaptured\"],\n",
    "        \"PaymentCaptured\": [],\n",
    "    }\n",
    "\n",
    "    records = []\n",
    "    for src, to_list in transitions.items():\n",
    "        records.append({\n",
    "            \"From\": src,\n",
    "            \"To_List\": str(to_list)  # stringified Python list\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records, columns=[\"From\", \"To_List\"])\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 2. Attribute-driven verification logic\n",
    "# ================================================================\n",
    "\n",
    "def determine_verification_outcome(\n",
    "    category: str,\n",
    "    region: str,\n",
    "    wallet_balance: float,\n",
    "    outstanding_amount: float,\n",
    "    credit_rating: int\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Deterministically decide verification outcome based on\n",
    "    product category, customer region, wallet balance, outstanding\n",
    "    amount, and credit rating.\n",
    "\n",
    "    Returns one of:\n",
    "    - 'FAILED'\n",
    "    - 'MANUAL_REVIEW'\n",
    "    - 'AUTO_APPROVED'\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Fail rules (single / multi-attribute) ----\n",
    "    # 1) Product type triggers failure\n",
    "    if category == \"APPAREL\":\n",
    "        return \"FAILED\"\n",
    "\n",
    "    # 2) Customer region triggers failure\n",
    "    if region == \"NORTH\":\n",
    "        return \"FAILED\"\n",
    "\n",
    "    # 3) Wallet balance too small\n",
    "    if wallet_balance < 10:\n",
    "        return \"FAILED\"\n",
    "\n",
    "    # 4) Two-way combination: Apparel + NORTH\n",
    "    if category == \"APPAREL\" and region == \"NORTH\":\n",
    "        return \"FAILED\"\n",
    "\n",
    "    # 5) Two-way combination: Apparel + low wallet\n",
    "    if category == \"APPAREL\" and wallet_balance < 20:\n",
    "        return \"FAILED\"\n",
    "\n",
    "    # 6) Three-way combination: Electronics + high debt + poor credit\n",
    "    if category == \"ELECTRONICS\" and outstanding_amount > 100 and credit_rating <= 2:\n",
    "        return \"FAILED\"\n",
    "\n",
    "    # ---- Manual review rules ----\n",
    "    # 7) Medium-risk credit rating\n",
    "    if credit_rating == 3:\n",
    "        return \"MANUAL_REVIEW\"\n",
    "\n",
    "    # 8) Moderate outstanding debt\n",
    "    if 10 <= outstanding_amount < 100:\n",
    "        return \"MANUAL_REVIEW\"\n",
    "\n",
    "    # 9) Medium wallet range\n",
    "    if 10 <= wallet_balance < 20:\n",
    "        return \"MANUAL_REVIEW\"\n",
    "\n",
    "    # ---- Default: auto-approve ----\n",
    "    return \"AUTO_APPROVED\"\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 3. Reference data generators (customers, restaurants, etc.)\n",
    "# ================================================================\n",
    "\n",
    "def generate_customers(n_customers: int = 1000) -> pd.DataFrame:\n",
    "    customer_ids = np.arange(1, n_customers + 1)\n",
    "\n",
    "    regions = [\"NORTH\", \"SOUTH\", \"EAST\", \"WEST\"]\n",
    "    credit_ratings = [1, 2, 3, 4, 5]\n",
    "\n",
    "    # Skew so we get enough failures and manual reviews\n",
    "    region_choices = rng.choice(regions, size=n_customers, p=[0.25, 0.25, 0.25, 0.25])\n",
    "    credit_choices = rng.choice(credit_ratings, size=n_customers, p=[0.1, 0.2, 0.3, 0.25, 0.15])\n",
    "    outstanding = rng.uniform(0, 200, size=n_customers).round(2)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"customer_id\": customer_ids,\n",
    "        \"region\": region_choices,\n",
    "        \"outstanding_amount\": outstanding,\n",
    "        \"credit_rating\": credit_choices,\n",
    "        \"created_ts\": pd.Timestamp(\"2024-01-01\") +\n",
    "                      pd.to_timedelta(rng.integers(0, 60, size=n_customers), unit=\"D\")\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_customer_addresses(customers: pd.DataFrame) -> pd.DataFrame:\n",
    "    records = []\n",
    "    address_id = 1\n",
    "\n",
    "    for _, row in customers.iterrows():\n",
    "        # 1–3 addresses per customer\n",
    "        n_addr = rng.integers(1, 4)\n",
    "        for _ in range(n_addr):\n",
    "            records.append({\n",
    "                \"address_id\": address_id,\n",
    "                \"cust_ref\": row[\"customer_id\"],\n",
    "                \"address_line\": f\"{address_id} Example Street\",\n",
    "                \"zone\": row[\"region\"],  # align zone with region for simplicity\n",
    "            })\n",
    "            address_id += 1\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "def generate_customer_payment_methods(customers: pd.DataFrame) -> pd.DataFrame:\n",
    "    methods = []\n",
    "    pay_id = 1\n",
    "    types = [\"CARD\", \"WALLET\", \"BANK\"]\n",
    "\n",
    "    for _, row in customers.iterrows():\n",
    "        # Each customer gets 1–2 methods\n",
    "        n_methods = rng.integers(1, 3)\n",
    "        for _ in range(n_methods):\n",
    "            method_type = rng.choice(types)\n",
    "            # Wallet balance only relevant if WALLET\n",
    "            wallet_balance = float(\n",
    "                rng.uniform(0, 200) if method_type == \"WALLET\" else rng.uniform(20, 200)\n",
    "            )\n",
    "            methods.append({\n",
    "                \"pay_method_id\": pay_id,\n",
    "                \"cust_ref\": row[\"customer_id\"],\n",
    "                \"method_type\": method_type,\n",
    "                \"wallet_balance\": round(wallet_balance, 2),\n",
    "                \"risk_category\": rng.choice([\"LOW\", \"MEDIUM\", \"HIGH\"], p=[0.6, 0.3, 0.1]),\n",
    "            })\n",
    "            pay_id += 1\n",
    "\n",
    "    return pd.DataFrame(methods)\n",
    "\n",
    "\n",
    "def generate_restaurants(n_restaurants: int = 50) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    rest_ids = np.arange(1, n_restaurants + 1)\n",
    "    restaurants = pd.DataFrame({\n",
    "        \"restaurant_id\": rest_ids,\n",
    "        \"name\": [f\"Restaurant_{i}\" for i in rest_ids],\n",
    "        \"cuisine\": rng.choice([\"ITALIAN\", \"INDIAN\", \"CHINESE\", \"BURGER\", \"DESSERT\"],\n",
    "                              size=n_restaurants),\n",
    "        \"rating\": rng.uniform(3.0, 5.0, size=n_restaurants).round(1),\n",
    "    })\n",
    "\n",
    "    # 1–3 branches per restaurant\n",
    "    branches = []\n",
    "    branch_id = 1\n",
    "    for rest_id in rest_ids:\n",
    "        n_branches = rng.integers(1, 4)\n",
    "        for _ in range(n_branches):\n",
    "            branches.append({\n",
    "                \"branch_id\": branch_id,\n",
    "                \"rest_ref\": rest_id,\n",
    "                \"address_line\": f\"Branch_{branch_id} Street\",\n",
    "                \"opening_hours\": \"09:00-22:00\",\n",
    "            })\n",
    "            branch_id += 1\n",
    "\n",
    "    branches_df = pd.DataFrame(branches)\n",
    "    return restaurants, branches_df\n",
    "\n",
    "\n",
    "def generate_menu(branches: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    categories = [\"FOOD\", \"DRINK\", \"DESSERT\", \"APPAREL\", \"ELECTRONICS\"]\n",
    "    items = []\n",
    "    options = []\n",
    "    item_id = 1\n",
    "    option_id = 1\n",
    "\n",
    "    for _, br in branches.iterrows():\n",
    "        # Each branch has ~10 menu items\n",
    "        n_items = rng.integers(6, 12)\n",
    "        for _ in range(n_items):\n",
    "            cat = rng.choice(categories, p=[0.5, 0.2, 0.1, 0.1, 0.1])\n",
    "            price = float(rng.uniform(5, 50))\n",
    "            items.append({\n",
    "                \"item_id\": item_id,\n",
    "                \"branch_ref\": br[\"branch_id\"],\n",
    "                \"name\": f\"Item_{item_id}\",\n",
    "                \"category\": cat,\n",
    "                \"base_price\": round(price, 2),\n",
    "            })\n",
    "\n",
    "            # Add 0–3 options\n",
    "            n_opts = rng.integers(0, 4)\n",
    "            for _ in range(n_opts):\n",
    "                options.append({\n",
    "                    \"option_id\": option_id,\n",
    "                    \"menu_ref\": item_id,\n",
    "                    \"option_name\": rng.choice([\"LARGE\", \"EXTRA_CHEESE\", \"SPICY\", \"ADD_ON\"]),\n",
    "                    \"extra_price\": round(float(rng.uniform(0.5, 5)), 2),\n",
    "                })\n",
    "                option_id += 1\n",
    "\n",
    "            item_id += 1\n",
    "\n",
    "    return pd.DataFrame(items), pd.DataFrame(options)\n",
    "\n",
    "\n",
    "def generate_drivers(n_drivers: int = 300) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    driver_ids = np.arange(1, n_drivers + 1)\n",
    "    drivers = pd.DataFrame({\n",
    "        \"driver_id\": driver_ids,\n",
    "        \"name\": [f\"Driver_{i}\" for i in driver_ids],\n",
    "        \"rating\": rng.uniform(3.0, 5.0, size=n_drivers).round(1),\n",
    "        \"region\": rng.choice([\"NORTH\", \"SOUTH\", \"EAST\", \"WEST\"], size=n_drivers),\n",
    "    })\n",
    "\n",
    "    vehicles = []\n",
    "    vehicle_id = 1\n",
    "    for d_id in driver_ids:\n",
    "        vehicles.append({\n",
    "            \"vehicle_id\": vehicle_id,\n",
    "            \"owner_driver_ref\": d_id,\n",
    "            \"vehicle_type\": rng.choice([\"BIKE\", \"CAR\", \"SCOOTER\"]),\n",
    "            \"plate\": f\"PLATE_{vehicle_id}\",\n",
    "        })\n",
    "        vehicle_id += 1\n",
    "\n",
    "    return drivers, pd.DataFrame(vehicles)\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 4. Main order + event generation\n",
    "# ================================================================\n",
    "\n",
    "def generate_orders_and_events(\n",
    "    n_traces: int,\n",
    "    customers: pd.DataFrame,\n",
    "    addresses: pd.DataFrame,\n",
    "    pay_methods: pd.DataFrame,\n",
    "    restaurants: pd.DataFrame,\n",
    "    branches: pd.DataFrame,\n",
    "    menu_items: pd.DataFrame,\n",
    "    menu_options: pd.DataFrame,\n",
    "    drivers: pd.DataFrame\n",
    ") -> Tuple[Dict[str, pd.DataFrame], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generate orders and all fact tables, plus event_traces DataFrame.\n",
    "    \"\"\"\n",
    "    # Initialise collection containers for each table\n",
    "    orders = []\n",
    "    order_items = []\n",
    "    order_discounts = []\n",
    "    order_status_events = []\n",
    "\n",
    "    kitchen_tickets = []\n",
    "    delivery_requests = []\n",
    "    delivery_assignments = []\n",
    "    delivery_status_events = []\n",
    "    payment_auths = []\n",
    "    payment_caps = []\n",
    "    support_tickets = []\n",
    "    verification_requests = []\n",
    "    verification_results = []\n",
    "    manual_reviews = []\n",
    "\n",
    "    event_trace_records = []\n",
    "\n",
    "    # Convenient lookups\n",
    "    cust_idx = customers.set_index(\"customer_id\")\n",
    "    addr_by_cust = addresses.groupby(\"cust_ref\")[\"address_id\"].apply(list).to_dict()\n",
    "    pay_by_cust = pay_methods.groupby(\"cust_ref\")[\"pay_method_id\"].apply(list).to_dict()\n",
    "    branch_ids = branches[\"branch_id\"].to_list()\n",
    "    drivers_ids = drivers[\"driver_id\"].to_list()\n",
    "\n",
    "    menu_items_idx = menu_items.set_index(\"item_id\")\n",
    "\n",
    "    # ID counters\n",
    "    order_id = 1\n",
    "    status_event_id = 1\n",
    "    ticket_id = 1\n",
    "    del_req_id = 1\n",
    "    del_assign_id = 1\n",
    "    del_evt_id = 1\n",
    "    auth_id = 1\n",
    "    cap_id = 1\n",
    "    supp_ticket_id = 1\n",
    "    veri_req_id = 1\n",
    "    veri_res_id = 1\n",
    "    manual_review_id = 1\n",
    "    order_item_id = 1\n",
    "    discount_row_id = 1\n",
    "\n",
    "    for _ in range(n_traces):\n",
    "        # -------------------------\n",
    "        # Basic foreign key choices\n",
    "        # -------------------------\n",
    "        cust_id = int(rng.choice(customers[\"customer_id\"].to_numpy()))\n",
    "        cust_row = cust_idx.loc[cust_id]\n",
    "\n",
    "        addr_choices = addr_by_cust[cust_id]\n",
    "        addr_id = int(rng.choice(addr_choices))\n",
    "\n",
    "        pay_choices = pay_by_cust[cust_id]\n",
    "        pm_id = int(rng.choice(pay_choices))\n",
    "        pm_row = pay_methods.loc[pay_methods[\"pay_method_id\"] == pm_id].iloc[0]\n",
    "\n",
    "        branch_id = int(rng.choice(branch_ids))\n",
    "\n",
    "        # Pick one menu item from that branch\n",
    "        branch_menu = menu_items[menu_items[\"branch_ref\"] == branch_id]\n",
    "        if branch_menu.empty:\n",
    "            # Fallback: any menu item\n",
    "            item_row = menu_items.sample(1, random_state=int(rng.integers(0, 10_000))).iloc[0]\n",
    "        else:\n",
    "            item_row = branch_menu.sample(1, random_state=int(rng.integers(0, 10_000))).iloc[0]\n",
    "        item_id_val = int(item_row[\"item_id\"])\n",
    "\n",
    "        # quantity & optional discount\n",
    "        quantity = int(rng.integers(1, 5))\n",
    "        has_discount = rng.random() < 0.2\n",
    "        discount_amount = float(rng.uniform(1, 5)) if has_discount else 0.0\n",
    "\n",
    "        # -------------------------\n",
    "        # Verification outcome\n",
    "        # -------------------------\n",
    "        category = str(item_row[\"category\"])\n",
    "        region = str(cust_row[\"region\"])\n",
    "        wallet_balance = float(pm_row[\"wallet_balance\"])\n",
    "        outstanding_amount = float(cust_row[\"outstanding_amount\"])\n",
    "        credit_rating = int(cust_row[\"credit_rating\"])\n",
    "\n",
    "        veri_outcome = determine_verification_outcome(\n",
    "            category=category,\n",
    "            region=region,\n",
    "            wallet_balance=wallet_balance,\n",
    "            outstanding_amount=outstanding_amount,\n",
    "            credit_rating=credit_rating,\n",
    "        )\n",
    "\n",
    "        # -------------------------\n",
    "        # Build base events & join path\n",
    "        # -------------------------\n",
    "        events: List[str] = []\n",
    "        join_path: List[str] = []\n",
    "\n",
    "        key_uuid = str(uuid.uuid4())\n",
    "\n",
    "        # CustomerCreated\n",
    "        events.append(\"CustomerCreated\")\n",
    "        join_path.append(\"customers.customer_id\")\n",
    "\n",
    "        # OrderPlaced\n",
    "        events.append(\"OrderPlaced\")\n",
    "        join_path.append(\"orders.order_id\")\n",
    "\n",
    "        # Create order row\n",
    "        base_ts = pd.Timestamp(\"2024-02-01\") + pd.to_timedelta(\n",
    "            int(rng.integers(0, 60)), unit=\"D\"\n",
    "        )\n",
    "        orders.append({\n",
    "            \"order_id\": order_id,\n",
    "            \"cust_ref\": cust_id,\n",
    "            \"branch_ref\": branch_id,\n",
    "            \"primary_address_ref\": addr_id,\n",
    "            \"created_ts\": base_ts,\n",
    "        })\n",
    "\n",
    "        # Add order_items row\n",
    "        order_items.append({\n",
    "            \"order_item_id\": order_item_id,\n",
    "            \"order_fk\": order_id,\n",
    "            \"menu_ref\": item_id_val,\n",
    "            \"quantity\": quantity,\n",
    "        })\n",
    "        order_item_id += 1\n",
    "\n",
    "        # Discount row if applicable\n",
    "        if has_discount:\n",
    "            order_discounts.append({\n",
    "                \"discount_row_id\": discount_row_id,\n",
    "                \"ord_ref\": order_id,\n",
    "                \"discount_amount\": round(discount_amount, 2),\n",
    "            })\n",
    "            discount_row_id += 1\n",
    "\n",
    "        # VerificationStarted\n",
    "        events.append(\"VerificationStarted\")\n",
    "        join_path.append(\"verification_requests.veri_req_id\")\n",
    "        verification_requests.append({\n",
    "            \"veri_req_id\": veri_req_id,\n",
    "            \"order_ref\": order_id,\n",
    "            \"created_ts\": base_ts + pd.Timedelta(minutes=1),\n",
    "        })\n",
    "\n",
    "        # verification_results\n",
    "        result_status = None\n",
    "        if veri_outcome == \"FAILED\":\n",
    "            result_status = \"FAILED\"\n",
    "            events.append(\"VerificationFailed\")\n",
    "        elif veri_outcome == \"MANUAL_REVIEW\":\n",
    "            result_status = \"MANUAL_REVIEW\"\n",
    "            events.append(\"VerificationNeedsManualReview\")\n",
    "        else:\n",
    "            result_status = \"AUTO_APPROVED\"\n",
    "            events.append(\"VerificationAutoApproved\")\n",
    "\n",
    "        join_path.append(\"verification_results.veri_result_id\")\n",
    "        verification_results.append({\n",
    "            \"veri_result_id\": veri_res_id,\n",
    "            \"req_ref\": veri_req_id,\n",
    "            \"result_status\": result_status,\n",
    "            \"result_ts\": base_ts + pd.Timedelta(minutes=2),\n",
    "        })\n",
    "\n",
    "        veri_req_id += 1\n",
    "        veri_res_id += 1\n",
    "\n",
    "        # Track if the order will continue to fulfillment\n",
    "        continue_to_fulfillment = True\n",
    "\n",
    "        # Manual review branch if needed\n",
    "        if veri_outcome == \"MANUAL_REVIEW\":\n",
    "            events.append(\"ManualReviewCompleted\")\n",
    "            join_path.append(\"manual_reviews.review_id\")\n",
    "\n",
    "            # 10% rejected, 90% approved\n",
    "            is_rejected = (rng.random() < 0.1)\n",
    "            review_outcome = \"REJECTED\" if is_rejected else \"APPROVED\"\n",
    "\n",
    "            manual_reviews.append({\n",
    "                \"review_id\": manual_review_id,\n",
    "                \"result_ref\": veri_res_id - 1,\n",
    "                \"review_outcome\": review_outcome,\n",
    "                \"review_ts\": base_ts + pd.Timedelta(minutes=5),\n",
    "            })\n",
    "            manual_review_id += 1\n",
    "\n",
    "            if is_rejected:\n",
    "                # Manual review rejected\n",
    "                events.append(\"OrderRejected\")\n",
    "                join_path.append(\"order_status_events.status_event_id\")\n",
    "                order_status_events.append({\n",
    "                    \"status_event_id\": status_event_id,\n",
    "                    \"order_ref\": order_id,\n",
    "                    \"status\": \"REJECTED\",\n",
    "                    \"event_ts\": base_ts + pd.Timedelta(minutes=6),\n",
    "                })\n",
    "                status_event_id += 1\n",
    "                continue_to_fulfillment = False\n",
    "\n",
    "        elif veri_outcome == \"FAILED\":\n",
    "            # Immediate rejection\n",
    "            events.append(\"OrderRejected\")\n",
    "            join_path.append(\"order_status_events.status_event_id\")\n",
    "            order_status_events.append({\n",
    "                \"status_event_id\": status_event_id,\n",
    "                \"order_ref\": order_id,\n",
    "                \"status\": \"REJECTED\",\n",
    "                \"event_ts\": base_ts + pd.Timedelta(minutes=3),\n",
    "            })\n",
    "            status_event_id += 1\n",
    "            continue_to_fulfillment = False\n",
    "\n",
    "        # If rejected at verification or manual review, we stop here\n",
    "        if not continue_to_fulfillment:\n",
    "            event_trace_records.append({\n",
    "                \"Key_Selector\": \"Order_ID\",\n",
    "                \"Key_ID\": key_uuid,\n",
    "                \"Event_Trace\": str(events),\n",
    "                \"Join_Path\": str(join_path),\n",
    "            })\n",
    "            order_id += 1\n",
    "            continue\n",
    "\n",
    "        # ------------------------------------------------\n",
    "        # Fulfillment path: OrderConfirmed all the way to Payment\n",
    "        # ------------------------------------------------\n",
    "        events.append(\"OrderConfirmed\")\n",
    "        join_path.append(\"order_status_events.status_event_id\")\n",
    "        order_status_events.append({\n",
    "            \"status_event_id\": status_event_id,\n",
    "            \"order_ref\": order_id,\n",
    "            \"status\": \"CONFIRMED\",\n",
    "            \"event_ts\": base_ts + pd.Timedelta(minutes=4),\n",
    "        })\n",
    "        status_event_id += 1\n",
    "\n",
    "        # Kitchen\n",
    "        events.append(\"KitchenStarted\")\n",
    "        join_path.append(\"kitchen_tickets.ticket_id\")\n",
    "        kitchen_tickets.append({\n",
    "            \"ticket_id\": ticket_id,\n",
    "            \"ticket_order_id\": order_id,\n",
    "            \"created_ts\": base_ts + pd.Timedelta(minutes=5),\n",
    "        })\n",
    "\n",
    "        events.append(\"KitchenCompleted\")\n",
    "        join_path.append(\"kitchen_tickets.ticket_id\")\n",
    "        kitchen_tickets[-1][\"completed_ts\"] = base_ts + pd.Timedelta(minutes=20)\n",
    "        ticket_id += 1\n",
    "\n",
    "        # Delivery / driver assignment\n",
    "        events.append(\"DriverAssigned\")\n",
    "        join_path.append(\"delivery_assignments.assignment_id\")\n",
    "        delivery_requests.append({\n",
    "            \"request_id\": del_req_id,\n",
    "            \"src_order_id\": order_id,\n",
    "            \"pickup_branch_ref\": branch_id,\n",
    "            \"dropoff_addr_ref\": addr_id,\n",
    "            \"created_ts\": base_ts + pd.Timedelta(minutes=21),\n",
    "        })\n",
    "\n",
    "        driver_id = int(rng.choice(drivers_ids))\n",
    "        delivery_assignments.append({\n",
    "            \"assignment_id\": del_assign_id,\n",
    "            \"req_ref\": del_req_id,\n",
    "            \"courier_ref\": driver_id,\n",
    "            \"assigned_ts\": base_ts + pd.Timedelta(minutes=22),\n",
    "        })\n",
    "\n",
    "        # Delivery status events\n",
    "        events.extend([\"DriverAtRestaurant\", \"PickupComplete\", \"OnTheWay\", \"Delivered\"])\n",
    "        for status in [\"AT_RESTAURANT\", \"PICKED_UP\", \"ON_THE_WAY\", \"DELIVERED\"]:\n",
    "            delivery_status_events.append({\n",
    "                \"delivery_evt_id\": del_evt_id,\n",
    "                \"route_assignment_id\": del_assign_id,\n",
    "                \"status\": status,\n",
    "                \"event_ts\": base_ts + pd.Timedelta(minutes=23 + del_evt_id - del_evt_id),\n",
    "            })\n",
    "            del_evt_id += 1\n",
    "        join_path.append(\"delivery_status_events.delivery_evt_id\")\n",
    "\n",
    "        del_req_id += 1\n",
    "        del_assign_id += 1\n",
    "\n",
    "        # Branch at Delivered: maybe support issue\n",
    "        support_issue = (rng.random() < 0.2)\n",
    "\n",
    "        if support_issue:\n",
    "            events.append(\"SupportTicketOpened\")\n",
    "            join_path.append(\"support_tickets.ticket_id\")\n",
    "            support_tickets.append({\n",
    "                \"ticket_id\": supp_ticket_id,\n",
    "                \"issue_order_ref\": order_id,\n",
    "                \"cust_ref\": cust_id,\n",
    "                \"opened_ts\": base_ts + pd.Timedelta(minutes=40),\n",
    "            })\n",
    "\n",
    "            events.append(\"VoucherIssued\")\n",
    "            join_path.append(\"support_tickets.ticket_id\")\n",
    "            support_tickets[-1][\"closed_ts\"] = base_ts + pd.Timedelta(minutes=50)\n",
    "            supp_ticket_id += 1\n",
    "\n",
    "        # Payment authorization & capture\n",
    "        events.append(\"PaymentAuthorized\")\n",
    "        join_path.append(\"payment_authorizations.auth_id\")\n",
    "        payment_auths.append({\n",
    "            \"auth_id\": auth_id,\n",
    "            \"auth_order_ref\": order_id,\n",
    "            \"method_ref\": pm_id,\n",
    "            \"auth_amount\": float(item_row[\"base_price\"]) * quantity - discount_amount,\n",
    "            \"status\": \"AUTHORIZED\",\n",
    "            \"auth_ts\": base_ts + pd.Timedelta(minutes=55),\n",
    "        })\n",
    "\n",
    "        events.append(\"PaymentCaptured\")\n",
    "        join_path.append(\"payment_captures.capture_id\")\n",
    "        payment_caps.append({\n",
    "            \"capture_id\": cap_id,\n",
    "            \"initial_auth_ref\": auth_id,\n",
    "            \"fee_order_ref\": order_id,\n",
    "            \"captured_amount\": float(item_row[\"base_price\"]) * quantity - discount_amount,\n",
    "            \"captured_ts\": base_ts + pd.Timedelta(minutes=60),\n",
    "        })\n",
    "\n",
    "        auth_id += 1\n",
    "        cap_id += 1\n",
    "\n",
    "        # Record the full trace\n",
    "        event_trace_records.append({\n",
    "            \"Key_Selector\": \"Order_ID\",\n",
    "            \"Key_ID\": key_uuid,\n",
    "            \"Event_Trace\": str(events),\n",
    "            \"Join_Path\": str(join_path),\n",
    "        })\n",
    "\n",
    "        # Increment order id\n",
    "        order_id += 1\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Convert everything into DataFrames\n",
    "    # ------------------------------------------------\n",
    "    tables = {\n",
    "        \"orders\": pd.DataFrame(orders),\n",
    "        \"order_items\": pd.DataFrame(order_items),\n",
    "        \"order_discounts\": pd.DataFrame(order_discounts),\n",
    "        \"order_status_events\": pd.DataFrame(order_status_events),\n",
    "        \"kitchen_tickets\": pd.DataFrame(kitchen_tickets),\n",
    "        \"delivery_requests\": pd.DataFrame(delivery_requests),\n",
    "        \"delivery_assignments\": pd.DataFrame(delivery_assignments),\n",
    "        \"delivery_status_events\": pd.DataFrame(delivery_status_events),\n",
    "        \"payment_authorizations\": pd.DataFrame(payment_auths),\n",
    "        \"payment_captures\": pd.DataFrame(payment_caps),\n",
    "        \"support_tickets\": pd.DataFrame(support_tickets),\n",
    "        \"verification_requests\": pd.DataFrame(verification_requests),\n",
    "        \"verification_results\": pd.DataFrame(verification_results),\n",
    "        \"manual_reviews\": pd.DataFrame(manual_reviews),\n",
    "    }\n",
    "\n",
    "    event_traces_df = pd.DataFrame(\n",
    "        event_trace_records,\n",
    "        columns=[\"Key_Selector\", \"Key_ID\", \"Event_Trace\", \"Join_Path\"]\n",
    "    )\n",
    "\n",
    "    return tables, event_traces_df\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 5. High-level generator\n",
    "# ================================================================\n",
    "\n",
    "def generate_food_delivery_dataset(\n",
    "    n_traces: int = N_TRACES,\n",
    "    data_dir: str = DATA_DIR\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generate the full synthetic food delivery dataset:\n",
    "    - 23 relational tables under ./data\n",
    "    - event_traces.csv\n",
    "    - transition_graph.csv\n",
    "    - README.md\n",
    "    \"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    # Reference tables\n",
    "    customers = generate_customers()\n",
    "    addresses = generate_customer_addresses(customers)\n",
    "    pay_methods = generate_customer_payment_methods(customers)\n",
    "    restaurants, branches = generate_restaurants()\n",
    "    menu_items, menu_options = generate_menu(branches)\n",
    "    drivers, vehicles = generate_drivers()\n",
    "\n",
    "    # Core fact tables & event traces\n",
    "    fact_tables, event_traces = generate_orders_and_events(\n",
    "        n_traces=n_traces,\n",
    "        customers=customers,\n",
    "        addresses=addresses,\n",
    "        pay_methods=pay_methods,\n",
    "        restaurants=restaurants,\n",
    "        branches=branches,\n",
    "        menu_items=menu_items,\n",
    "        menu_options=menu_options,\n",
    "        drivers=drivers,\n",
    "    )\n",
    "\n",
    "    # Transition graph\n",
    "    transition_graph = build_transition_graph()\n",
    "\n",
    "    # Save core CSVs (root)\n",
    "    event_traces.to_csv(\"event_traces.csv\", index=False)\n",
    "    transition_graph.to_csv(\"transition_graph.csv\", index=False)\n",
    "\n",
    "    # Save reference tables\n",
    "    customers.to_csv(os.path.join(data_dir, \"customers.csv\"), index=False)\n",
    "    addresses.to_csv(os.path.join(data_dir, \"customer_addresses.csv\"), index=False)\n",
    "    pay_methods.to_csv(os.path.join(data_dir, \"customer_payment_methods.csv\"), index=False)\n",
    "    restaurants.to_csv(os.path.join(data_dir, \"restaurants.csv\"), index=False)\n",
    "    branches.to_csv(os.path.join(data_dir, \"restaurant_locations.csv\"), index=False)\n",
    "    menu_items.to_csv(os.path.join(data_dir, \"menu_items.csv\"), index=False)\n",
    "    menu_options.to_csv(os.path.join(data_dir, \"menu_item_options.csv\"), index=False)\n",
    "    drivers.to_csv(os.path.join(data_dir, \"drivers.csv\"), index=False)\n",
    "    vehicles.to_csv(os.path.join(data_dir, \"driver_vehicles.csv\"), index=False)\n",
    "\n",
    "    # Save fact tables\n",
    "    for name, df in fact_tables.items():\n",
    "        df.to_csv(os.path.join(data_dir, f\"{name}.csv\"), index=False)\n",
    "\n",
    "\n",
    "    print(f\"Generated {len(event_traces)} traces and saved tables to '{data_dir}'\")\n",
    "\n",
    "\n",
    "\n",
    "generate_food_delivery_dataset(10000, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ef48b0-6f69-402c-900e-71e888025ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tables...\n",
      "Applying attribute drift...\n",
      "Applying timestamp missingness...\n",
      "Saving noisy tables...\n",
      "Noise injection complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joel\\AppData\\Local\\Temp\\ipykernel_1163384\\4231154249.py:122: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NaT' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[missing_indices, col] = pd.NaT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# CONFIGURATION\n",
    "# ===============================================================\n",
    "\n",
    "ATTRIBUTE_SWAP_RATIO = 0.30     # 30% schema drift\n",
    "TIMESTAMP_MISSING_RATIO = 0.15  # 15% timestamp missingness\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 1. ATTRIBUTE SWAP LOGIC\n",
    "# ===============================================================\n",
    "\n",
    "def get_safe_columns(df: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Identify safe-to-swap columns:\n",
    "    - Excludes PK columns\n",
    "    - Excludes FK columns\n",
    "    - Excludes timestamp columns\n",
    "    - Excludes numeric IDs & join keys\n",
    "    \"\"\"\n",
    "    pk_like = {\"id\", \"pk\", \"_id\", \"order_ref\", \"cust_ref\", \"branch_ref\",\n",
    "               \"menu_ref\", \"req_ref\", \"result_ref\", \"assignment_id\"}\n",
    "    \n",
    "    ts_like = {\"ts\", \"time\", \"timestamp\"}\n",
    "\n",
    "    safe_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        \n",
    "        if any(k in col_lower for k in pk_like):\n",
    "            continue\n",
    "        if any(t in col_lower for t in ts_like):\n",
    "            continue\n",
    "        if df[col].dtype == \"datetime64[ns]\":\n",
    "            continue\n",
    "\n",
    "        safe_cols.append(col)\n",
    "\n",
    "    return safe_cols\n",
    "\n",
    "\n",
    "def apply_attribute_swap_to_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform schema drift on safe columns:\n",
    "    - Random renaming\n",
    "    - Column value swapping\n",
    "    - Type transformation\n",
    "    \"\"\"\n",
    "    safe_cols = get_safe_columns(df)\n",
    "    if len(safe_cols) == 0:\n",
    "        return df\n",
    "\n",
    "    num_to_modify = int(len(safe_cols) * ATTRIBUTE_SWAP_RATIO)\n",
    "    chosen_cols = random.sample(safe_cols, num_to_modify)\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1. Rename columns\n",
    "    for col in chosen_cols:\n",
    "        new_name = f\"attr_{random.randint(100, 999)}\"\n",
    "        df.rename(columns={col: new_name}, inplace=True)\n",
    "\n",
    "    # 2. Swap values between columns (if at least two exist)\n",
    "    if len(chosen_cols) >= 2:\n",
    "        col1, col2 = random.sample(chosen_cols, 2)\n",
    "        df[col1], df[col2] = df[col2], df[col1]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_attribute_swap(tables: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Apply attribute drift to all tables except those requiring strict schema:\n",
    "    - Do NOT modify event_traces or transition_graph\n",
    "    - Only modify relational tables\n",
    "    \"\"\"\n",
    "    new_tables = {}\n",
    "\n",
    "    for name, df in tables.items():\n",
    "        drifted = apply_attribute_swap_to_table(df)\n",
    "        new_tables[name] = drifted\n",
    "\n",
    "    return new_tables\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 2. TIMESTAMP MISSINGNESS LOGIC\n",
    "# ===============================================================\n",
    "\n",
    "def get_timestamp_columns(df: pd.DataFrame) -> List[str]:\n",
    "    return [\n",
    "        col for col in df.columns\n",
    "        if df[col].dtype == \"datetime64[ns]\" or \"ts\" in col.lower()\n",
    "    ]\n",
    "\n",
    "\n",
    "def apply_timestamp_missingness(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove timestamps from 15% of the rows for all timestamp-bearing columns.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    ts_cols = get_timestamp_columns(df)\n",
    "\n",
    "    if len(ts_cols) == 0:\n",
    "        return df\n",
    "\n",
    "    for col in ts_cols:\n",
    "        n = len(df)\n",
    "        num_missing = int(n * TIMESTAMP_MISSING_RATIO)\n",
    "        missing_indices = rng.choice(n, size=num_missing, replace=False)\n",
    "        df.loc[missing_indices, col] = pd.NaT\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_timestamp_missingness_to_tables(tables: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:\n",
    "    new_tables = {}\n",
    "\n",
    "    for name, df in tables.items():\n",
    "        new_tables[name] = apply_timestamp_missingness(df)\n",
    "\n",
    "    return new_tables\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 3. COMBINED NOISE PIPELINE\n",
    "# ===============================================================\n",
    "\n",
    "def inject_noise(data_dir: str = \"./data\"):\n",
    "    \"\"\"\n",
    "    Post-process all generated CSV tables in data_dir with:\n",
    "    - 30% schema drift (attribute swap)\n",
    "    - 15% timestamp missingness\n",
    "    \"\"\"\n",
    "    print(\"Loading tables...\")\n",
    "    tables = {}\n",
    "\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith(\".csv\"):\n",
    "            df = pd.read_csv(os.path.join(data_dir, file), parse_dates=True)\n",
    "            tables[file.replace(\".csv\", \"\")] = df\n",
    "\n",
    "    print(\"Applying attribute drift...\")\n",
    "    tables = apply_attribute_swap(tables)\n",
    "\n",
    "    print(\"Applying timestamp missingness...\")\n",
    "    tables = apply_timestamp_missingness_to_tables(tables)\n",
    "\n",
    "    # Save modified tables\n",
    "    print(\"Saving noisy tables...\")\n",
    "    for name, df in tables.items():\n",
    "        df.to_csv(os.path.join(data_dir, f\"{name}.csv\"), index=False)\n",
    "\n",
    "    print(\"Noise injection complete.\")\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 4. ENTRY POINT (optional)\n",
    "# ===============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inject_noise()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
